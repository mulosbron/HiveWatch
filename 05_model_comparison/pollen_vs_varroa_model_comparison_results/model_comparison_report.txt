# YOLO Model Comparison Report

Date: 2025-06-20 20:23:25
Number of test samples: 500
Confidence threshold: 0.45
IoU threshold for matching: 0.15

## Models Evaluated

1. C:\Users\duggy\OneDrive\Belgeler\Github\HiveWatch\05_model_comparison\..\03_model_training\runs\detect\pollen_varroa_model_50_320_pre\weights\best.pt
2. C:\Users\duggy\OneDrive\Belgeler\Github\HiveWatch\05_model_comparison\..\03_model_training\runs\detect\pollen_varroa_model_50_448_pre\weights\best.pt
3. C:\Users\duggy\OneDrive\Belgeler\Github\HiveWatch\05_model_comparison\..\03_model_training\runs\detect\pollen_varroa_model_50_640_pre\weights\best.pt

## Overall Results Summary

| Metric | pollen_varroa_model_50_320_pre | pollen_varroa_model_50_448_pre | pollen_varroa_model_50_640_pre |
|----------|------------|------------|------------|
| Detection Precision | 0.8045 | 0.8319 | 0.8771 | 
| Detection Recall | 0.2493 | 0.2949 | 0.2056 | 
| Detection F1-Score | 0.3806 | 0.4355 | 0.3331 | 
| Classification Accuracy | 1.0000 | 0.9966 | 0.9855 | 
| Class Match Rate | 1.0000 | 0.9966 | 0.9855 | 
| mAP Score | 1.0000 | 0.9944 | 0.9862 | 
| Average IoU | 0.7585 | 0.7328 | 0.7552 | 
| Avg Inference Time (ms) | 34.50 ms | 10.30 ms | 16.55 ms | 

## Detailed Results for pollen_varroa_model_50_320_pre

### Confusion Matrix

```
             | Pred Pollen | Pred Varroa |
True Pollen (0) |        98 |         0 |
True Varroa (1)|         0 |       153 |
```

### Class-specific Metrics

```
           | Pollen (0)  | Varroa (1) |
Precision  | 1.0000 | 1.0000 |
Recall     | 1.0000 | 1.0000 |
F1-Score   | 1.0000 | 1.0000 |
```

### Detection Counts

- True Positives: 251
- False Positives: 61
- False Negatives: 756

## Detailed Results for pollen_varroa_model_50_448_pre

### Confusion Matrix

```
             | Pred Pollen | Pred Varroa |
True Pollen (0) |        88 |         1 |
True Varroa (1)|         0 |       208 |
```

### Class-specific Metrics

```
           | Pollen (0)  | Varroa (1) |
Precision  | 1.0000 | 0.9952 |
Recall     | 0.9888 | 1.0000 |
F1-Score   | 0.9944 | 0.9976 |
```

### Detection Counts

- True Positives: 297
- False Positives: 60
- False Negatives: 710

## Detailed Results for pollen_varroa_model_50_640_pre

### Confusion Matrix

```
             | Pred Pollen | Pred Varroa |
True Pollen (0) |        98 |         0 |
True Varroa (1)|         3 |       106 |
```

### Class-specific Metrics

```
           | Pollen (0)  | Varroa (1) |
Precision  | 0.9703 | 1.0000 |
Recall     | 1.0000 | 0.9725 |
F1-Score   | 0.9849 | 0.9860 |
```

### Detection Counts

- True Positives: 207
- False Positives: 29
- False Negatives: 800

## Conclusion

- Best model for overall detection (F1): pollen_varroa_model_50_448_pre
- Best model for classification accuracy: pollen_varroa_model_50_320_pre
- Best model for detection precision (IoU): pollen_varroa_model_50_320_pre
- Fastest model: pollen_varroa_model_50_448_pre

## Debug Notes

This evaluation was run with DEBUG=True. Check the debug_info.txt file for detailed information.
Common issues with model evaluation:
1. Coordinate format mismatch: YOLO uses normalized coordinates, but model may output pixel coordinates
2. IoU threshold too high: If boxes don't overlap enough, they won't match
3. Label paths incorrect: Make sure the ground truth label files are correctly paired with images
4. Class ID mismatch: Ensure that class IDs match between predictions and ground truth

Please refer to the generated visualization files for more detailed comparisons.
